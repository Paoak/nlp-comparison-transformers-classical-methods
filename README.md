# Сравнение трансформеров и классических методов для анализа текстов

Данный проект посвящён исследованию и сравнению двух подходов к задаче анализа текстов на примере датасета отзывов IMDb:  
**классических методов машинного обучения** и **современных нейросетевых моделей на основе трансформеров**. 

В работе последовательно реализованы этапы, начиная от подготовки данных и заканчивая финальной оценкой и сравнением моделей.  
Цель проекта — понять, насколько современные архитектуры превосходят традиционные алгоритмы в задаче классификации текста, а также выявить их сильные и слабые стороны.

[*Оригинальный файл рабочей тетради c проектом*](https://colab.research.google.com/drive/1M9bOSBKyKtrDDrQyp6UtWpBPq8TSQQRm#scrollTo=3NKGIxUkK4s1)

---

## Описание исследования

В ходе работы было выполнено следующее:

1. **Сбор и подготовка данных**  
   - Использован датасет IMDb с отзывами о фильмах, размеченными как *положительные* или *отрицательные*.  
   - Проведена очистка текста: удаление пунктуации, стоп-слов и приведение слов к нижнему регистру.  
   - Построена визуализация данных, включая частотные облака слов и распределение классов.

2. **Реализация классических методов**  
   - Применены модели:
     - Logistic Regression  
     - Support Vector Machine (SVM)  
     - Random Forest  
     - Naive Bayes
   - Использованы векторные представления текста
   - Оценка моделей проведена по метрикам: accuracy, precision, recall и F1-score.

3. **Реализация современных трансформеров**  
   - Использованы предобученные модели с библиотеки **Hugging Face Transformers**:
     - DistilBERT  
     - BERT-tiny
   - Выполнено дообучение моделей на размеченном датасете.
   - Для обучения применялись GPU-вычисления (Google Colab).

4. **Сравнительный анализ**  
   - Проведено сравнение качества моделей по основным метрикам.  
   - Проанализирована скорость обучения и требования к ресурсам.  
   - Сделаны выводы о применимости каждого подхода в реальных задачах.

---

## Итоги

В результате исследования было выявлено:

- **Классические методы** быстрее обучаются, проще в настройке и интерпретации, но показывают ограниченные результаты на сложных текстах.  
- **Трансформеры** достигают более высокой точности и F1-score благодаря учёту контекста слов, однако требуют значительно больше ресурсов и времени на обучение.  
- Для небольших и простых задач классические методы могут быть оптимальным выбором, в то время как для сложных проектов в области NLP оправдано использование трансформеров.

---

## Как запустить проект

1. **Через Google Colab**  
   - Откройте файл ноутбука [`nlp_comparison_transformers_classical_methods.ipynb`](nlp_comparison_transformers_classical_methods.ipynb).  
   - Выполните все ячейки последовательно.  
   - Все необходимые зависимости автоматически устанавливаются в первых ячейках.

2. **Локально**  
   ```bash
   git clone https://github.com/Paoak/nlp-comparison-transformers-classical-methods.git
   cd nlp-comparison-transformers-classical-methods
   pip install -r requirements.txt
   jupyter notebook
   ```
  - Откройте ноутбук в Jupyter и выполните его.

---
   
## Вывод

Работа демонстрирует эволюцию подходов к обработке естественного языка: от простых статистических методов до современных глубоких моделей.
Полученные результаты помогают понять, когда лучше применять классические алгоритмы, а когда стоит использовать трансформеры для достижения наилучшего качества.
